# Aeon AI Platform - Environment Configuration
# Copy this file to .env and update with your values

# ===== Host Configuration =====
# IP address of the host machine (where Podman services run)
# K8s pods will use this to connect to vLLM and embedding services
HOST_IP=192.168.1.100

# ===== Container Runtime =====
# Choose between 'docker' or 'podman' (recommended: podman for better isolation)
CONTAINER_RUNTIME=podman

# ===== Service Endpoints =====
# These are automatically configured when using Podman compose
# For K8s deployment, these will be updated to use HOST_IP

# vLLM Inference Server
VLLM_ENDPOINT=http://172.20.0.10:8000/v1
VLLM_HOST_ENDPOINT=http://${HOST_IP}:8000/v1

# Embedding Server
EMBEDDING_ENDPOINT=http://172.20.0.11:8001
EMBEDDING_HOST_ENDPOINT=http://${HOST_IP}:8001

# ===== Container Registry =====
REGISTRY=localhost:5000
REGISTRY_HOST=${HOST_IP}:5000

# Image tags
IMAGE_TAG=latest

# ===== Database Configuration =====

# Redis
REDIS_HOST=redis-master  # K8s service name, or 172.20.0.30 for Podman dev
REDIS_PORT=6379

# PostgreSQL
POSTGRES_HOST=postgres-postgresql  # K8s service name, or 172.20.0.31 for Podman dev
POSTGRES_PORT=5432
POSTGRES_DB=aiplatform
POSTGRES_USER=aiuser
POSTGRES_PASSWORD=changeme  # CHANGE THIS IN PRODUCTION!

# Qdrant Vector Database
QDRANT_HOST=http://qdrant.vector-db:6333  # K8s service name, or http://172.20.0.32:6333 for Podman dev

# ===== GPU Configuration =====
# CUDA device visibility (0 = first GPU, 0,1 = first two GPUs)
CUDA_VISIBLE_DEVICES=0

# vLLM GPU memory utilization (0.0 to 1.0)
GPU_MEMORY_UTILIZATION=0.6

# ===== Model Configuration =====
# LLM Model
LLM_MODEL=mistralai/Mistral-7B-Instruct-v0.3
MAX_MODEL_LEN=8192

# Embedding Model
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIM=384

# ===== Networking =====
# Podman network subnet
PODMAN_NETWORK_SUBNET=172.20.0.0/16

# Podman service IPs (used by podman-compose.yml)
VLLM_IP=172.20.0.10
EMBEDDING_IP=172.20.0.11
REGISTRY_IP=172.20.0.20
REDIS_DEV_IP=172.20.0.30
POSTGRES_DEV_IP=172.20.0.31
QDRANT_DEV_IP=172.20.0.32
BACKEND_DEV_IP=172.20.0.40
FRONTEND_DEV_IP=172.20.0.41

# ===== Kubernetes Configuration =====
# Ingress hostname
INGRESS_HOST=aeon.local

# Grafana NodePort
GRAFANA_NODEPORT=30001

# ===== Development Configuration =====
# Frontend dev server port
VITE_DEV_PORT=3000

# Backend dev server port
BACKEND_DEV_PORT=8080

# ===== Monitoring =====
# Grafana credentials (CHANGE IN PRODUCTION!)
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=prom-operator

# ===== Feature Flags =====
# Enable/disable features (true/false)
ENABLE_RAG=false
ENABLE_CODE_EXEC=false
ENABLE_WEB_SEARCH=false
ENABLE_ANALYTICS=false

# ===== Logging =====
LOG_LEVEL=info  # debug, info, warning, error, critical
