# Aeon AI Platform - Environment Configuration Template
# Copy this file to .env and customize for your environment
# IMPORTANT: Never commit .env to version control!

# ============================================================================
# SYSTEM PATHS
# ============================================================================

# Temporary directory for container builds (should have plenty of space)
TMPDIR=/tmp

# Podman runtime directory for temporary files
PODMAN_RUNROOT=/tmp/podman/runroot

# ============================================================================
# NETWORK CONFIGURATION
# ============================================================================

# Host IP address where inference services (vLLM, embeddings) will run
# This is used by K8s pods to reach services running on the host
HOST_IP=192.168.1.100

# ============================================================================
# DATABASE CREDENTIALS
# ============================================================================

# PostgreSQL credentials
POSTGRES_USER=aiuser
POSTGRES_PASSWORD=changeme_to_secure_password
POSTGRES_DB=aiplatform
POSTGRES_HOST=postgres-postgresql
POSTGRES_PORT=5432

# Redis configuration
REDIS_HOST=redis-master
REDIS_PORT=6379

# ============================================================================
# SERVICE ENDPOINTS
# ============================================================================

# vLLM inference endpoint (running on host)
VLLM_ENDPOINT=http://192.168.1.100:8000/v1

# Embedding service endpoint (running on host)
EMBEDDING_ENDPOINT=http://192.168.1.100:8001

# Qdrant vector database
QDRANT_HOST=http://qdrant.vector-db:6333

# SearXNG search engine (if deployed)
SEARXNG_ENDPOINT=http://searxng.search-engine:8080

# ============================================================================
# FEATURE FLAGS
# ============================================================================

ENABLE_RAG=true
ENABLE_AGENT=true
ENABLE_CODE_EXEC=true
ENABLE_ANALYTICS=true

# ============================================================================
# CONTAINER REGISTRY
# ============================================================================

# Local container registry for K8s deployments
REGISTRY_URL=localhost:5000

# ============================================================================
# GPU CONFIGURATION
# ============================================================================

# GPU memory utilization for vLLM (0.0 to 1.0)
GPU_MEMORY_UTILIZATION=0.6

# Maximum model context length
MAX_MODEL_LENGTH=8192

# ============================================================================
# MONITORING
# ============================================================================

# Grafana access
GRAFANA_PORT=30001
GRAFANA_USER=admin
GRAFANA_PASSWORD=prom-operator
