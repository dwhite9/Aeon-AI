# Aeon Inference Services Requirements

# LLM Serving
vllm>=0.6.0
bitsandbytes>=0.41.0

# Embeddings
sentence-transformers>=2.2.2
torch>=2.0.0

# API Framework
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.0.0

# Utilities
numpy>=1.24.0
